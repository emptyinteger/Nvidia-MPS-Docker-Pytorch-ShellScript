# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/176kmiGnv2wwboGFHR2UZHhSfjyEzFaVq

Modules import
"""

import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader

import torchvision
import torchvision.datasets
import torchvision.transforms as transforms

import numpy as np
import matplotlib.pyplot as plt

from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data.distributed import DistributedSampler
import torch.distributed as dist
import torch.optim as optim
import torch.multiprocessing as mp

import time
from datetime import datetime


learning_rate = 0.1
num_epoch = 60
plt.style.use('seaborn-white')

def imshow(img):
  img = img / 2 + 0.5 #노멀라이즈 되돌리기
  npimg = img.numpy()
  plt.imshow(np.transpose(npimg, (1, 2, 0)))
  plt.show()

import torch.nn as nn
import torch.nn.functional as F


class BasicBlock(nn.Module):
    mul = 1
    def __init__(self, in_planes, out_planes, stride=1):
        super(BasicBlock, self).__init__()
        
        # stride를 통해 너비와 높이 조정
        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_planes)
        
        # stride = 1, padding = 1이므로, 너비와 높이는 항시 유지됨
        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_planes)
        
        # x를 그대로 더해주기 위함
        self.shortcut = nn.Sequential()
        
        # 만약 size가 안맞아 합연산이 불가하다면, 연산 가능하도록 모양을 맞춰줌
        if stride != 1: # x와 
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(out_planes)
            )
    
    def forward(self, x):
        out = self.conv1(x)
        out = self.bn1(out)
        out = F.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)
        out += self.shortcut(x) # 필요에 따라 layer를 Skip
        out = F.relu(out)
        return out

class BottleNeck(nn.Module):
	# 논문의 구조를 참고하여 mul 값은 4로 지정, 즉, 64 -> 256
    mul = 4
    def __init__(self, in_planes, out_planes, stride=1):
        super(BottleNeck, self).__init__()
        
        #첫 Convolution은 너비와 높이 downsampling
        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)
        self.bn1 = nn.BatchNorm2d(out_planes)
        
        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_planes)
        
        self.conv3 = nn.Conv2d(out_planes, out_planes*self.mul, kernel_size=1, stride=1, bias=False)
        self.bn3 = nn.BatchNorm2d(out_planes*self.mul)
        
        self.shortcut = nn.Sequential()
        
        if stride != 1 or in_planes != out_planes*self.mul:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_planes, out_planes*self.mul, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(out_planes*self.mul)
            )
        
    def forward(self, x):
        out = self.conv1(x)
        out = self.bn1(out)
        out = F.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)
        out = F.relu(out)
        out = self.conv3(out)
        out = self.bn3(out)
        out += self.shortcut(x)
        out = F.relu(out)
        return out

class ResNet(nn.Module):
	# CIFAR-10을 학습시킬 것이므로, num_classes=10으로 설정
    def __init__(self, block, num_blocks, num_classes=10):
        super(ResNet, self).__init__()
        #RGB 3개채널에서 64개의 Kernel 사용 (논문 참고)
        self.in_planes = 64
        
        # Resnet 논문 구조의 conv1 파트 그대로 구현
        self.conv1 = nn.Conv2d(3, self.in_planes, kernel_size=7, stride=2, padding = 3)
        self.bn1 = nn.BatchNorm2d(self.in_planes)
        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        
        self.layer1 = self.make_layer(block, 64, num_blocks[0], stride=1)
        self.layer2 = self.make_layer(block, 128, num_blocks[1], stride=2)
        self.layer3 = self.make_layer(block, 256, num_blocks[2], stride=2)
        self.layer4 = self.make_layer(block, 512, num_blocks[3], stride=2)
        self.avgpool = nn.AdaptiveAvgPool2d((1,1))
        
        # Basic Resiudal Block일 경우 그대로, BottleNeck일 경우 4를 곱한다.
        self.linear = nn.Linear(512 * block.mul, num_classes)
        
    # 다양한 Architecture 생성을 위해 make_layer로 Sequential 생성     
    def make_layer(self, block, out_planes, num_blocks, stride):
        # layer 앞부분에서만 크기를 절반으로 줄이므로, 아래와 같은 구조
        strides = [stride] + [1] * (num_blocks-1)
        layers = []
        for i in range(num_blocks):
            layers.append(block(self.in_planes, out_planes, strides[i]))
            self.in_planes = block.mul * out_planes
        return nn.Sequential(*layers)
    
    def forward(self, x):
        out = self.conv1(x)
        out = self.bn1(out)
        out = F.relu(out)
        out = self.maxpool1(out)
        out = self.layer1(out)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.layer4(out)
        out = self.avgpool(out)
        out = torch.flatten(out,1)
        out = self.linear(out)
        return out

def ResNet18():
    return ResNet(BasicBlock, [2, 2, 2, 2])

def ResNet34():
    return ResNet(BasicBlock, [3, 4, 6, 3])

def ResNet50():
    return ResNet(BottleNeck, [3, 4, 6, 3])

def ResNet101():
    return ResNet(BottleNeck, [3, 4, 23, 3])

def ResNet152():
    return ResNet(BottleNeck, [3, 8, 36, 3])

# Simple Learning Rate Scheduler
def lr_scheduler(optimizer, epoch):
    lr = learning_rate
    if epoch >= 50:
        lr /= 10
    if epoch >= 100:
        lr /= 10
    for param_group in optimizer.param_groups:
        param_group['lr'] = lr

# Xavier         
def init_weights(m):
    if isinstance(m, nn.Linear):
        torch.nn.init.xavier_uniform(m.weight)
        m.bias.data.fill_(0.01)

def get_data_loader(batch_size, train=True, num_workers=4, pin_memory=True):
    dataset = torchvision.datasets.CIFAR10(root='~/data',
                                          train=train,
                                          download=True,
                                          transform=transforms.Compose([
                                              transforms.ToTensor(),
                                              transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))
                                        ]))
    sampler = DistributedSampler(dataset) if train else None
    loader = DataLoader(dataset, batch_size=batch_size, shuffle=(sampler is None),
                        num_workers=num_workers, pin_memory=pin_memory, sampler=sampler)
    return loader


def main():
  plt.style.use('seaborn-white')
  
  # 분산 환경 설정
  os.environ['MASTER_ADDR'] = 'localhost'
  os.environ['MASTER_PORT'] = '12355'
  torch.distributed.init_process_group(backend='nccl')  
  # 사용할 그래픽 카드 선택
  local_rank = torch.distributed.get_rank()
  torch.cuda.set_device(local_rank)

  device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
  world_size = torch.cuda.device_count()
  
  batch_size = 256
  train_loader = get_data_loader(batch_size)
  test_loader = get_data_loader(batch_size, train=False)



  classes = ('plane','car','bird','cat','deer','dog','frog','horse','ship','truck')

  # 학습용 이미지를 무작위로 가져오기
  dataiter = iter(train_loader)
  images, labels = next(dataiter)

  # 이미지 보여주기
  # imshow(torchvision.utils.make_grid(images))
  # 정답(label) 출력
  # print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))
  model = ResNet50()
  model.apply(init_weights)
  model = model.to(device)
  model = DDP(model, device_ids=[torch.cuda.current_device()])

  learning_rate = 0.1
  num_epoch = 60
  model_name = 'model.pth'
  
  loss_fn = nn.CrossEntropyLoss()
  optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0001)

  
  train_loss = 0
  valid_loss = 0
  correct = 0
  total_cnt = 0
  best_acc = 0
  start_time = time.time()

  # Arrays to store metrics
  train_accuracies = []
  valid_accuracies = []
  train_losses = []
  valid_losses = []


# Train
  for epoch in range(num_epoch):
    if dist.get_rank() == 0: # print only in main process
        print(f"====== { epoch+1 } epoch of { num_epoch } ======")
    model.train()
    lr_scheduler(optimizer, epoch)
    train_loss = torch.tensor(0.).to(device)
    correct = torch.tensor(0).to(device)
    total_cnt = torch.tensor(0).to(device)
    # Train Phase
    for step, batch in enumerate(train_loader):
        #  input and target
        batch[0], batch[1] = batch[0].to(device), batch[1].to(device)
        optimizer.zero_grad()

        logits = model(batch[0])
        loss = loss_fn(logits, batch[1])
        loss.backward()

        optimizer.step()
        train_loss += loss.detach()
        _, predict = logits.max(1)

        total_cnt += batch[1].size(0)
        correct += predict.eq(batch[1]).sum().item()

    # After the last batch in the epoch
    dist.all_reduce(train_loss)
    dist.all_reduce(total_cnt)
    dist.all_reduce(correct)
    if dist.get_rank() == 0: # print only in main process
        print(f"\nTrain Acc after Epoch : { correct.item() / total_cnt.item() }")
        print(f"Train Loss after Epoch : { train_loss.item() / total_cnt.item() }")
        train_accuracies.append(correct.item() / total_cnt.item())
        train_losses.append(train_loss.item() / total_cnt.item())

    valid_loss = torch.tensor(0.).to(device)
    correct = torch.tensor(0).to(device)
    total_cnt = torch.tensor(0).to(device)
    # Test Phase
    with torch.no_grad():
        model.eval()
        for step, batch in enumerate(test_loader):
            # input and target
            batch[0], batch[1] = batch[0].to(device), batch[1].to(device)
            total_cnt += batch[1].size(0)
            logits = model(batch[0])
            valid_loss += loss_fn(logits, batch[1]).detach()
            _, predict = logits.max(1)
            correct += predict.eq(batch[1]).sum().item()

        dist.all_reduce(valid_loss)
        dist.all_reduce(total_cnt)
        dist.all_reduce(correct)
        if dist.get_rank() == 0: # print only in main process
            valid_acc = correct.item() / total_cnt.item()
            print(f"\nValid Acc : { valid_acc }")    
            print(f"Valid Loss : { valid_loss.item() / total_cnt.item() }")
            valid_accuracies.append(valid_acc)
            valid_losses.append(valid_loss.item() / total_cnt.item())
            if(valid_acc > best_acc):
                best_acc = valid_acc
                torch.save(model, model_name)
                print("Model Saved!")
                
  end_time = time.time()  # 학습 종료 시간 기록
  elapsed_time = end_time - start_time  # 경과 시간 계산
  
  if dist.get_rank() == 0:
      print(f"Total training time: {elapsed_time:.2f} seconds")
      
      
  if dist.get_rank() == 0:
    # Visualization
    fig, ax1 = plt.subplots()

    color = 'tab:red'
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Accuracy', color=color)
    ax1.plot(range(1, epoch + 2), train_accuracies, color=color)
    ax1.tick_params(axis='y', labelcolor=color)
    ax1.set_ylim([0, 1])  # Y-Axis range for accuracy

    ax2 = ax1.twinx()
    color = 'tab:blue'
    ax2.set_ylabel('Loss', color=color)
    ax2.plot(range(1, epoch + 2), train_losses, color=color)
    ax2.tick_params(axis='y', labelcolor=color)
    ax2.set_ylim([0, 0.2])  # Y-Axis range for loss

    fig.tight_layout()
    plt.savefig(f'~/visualize/resnet50_{datetime.now().strftime("%Y%m%d%H%M%S")}.png')  # Save plot as png

if __name__ == '__main__':
    main()